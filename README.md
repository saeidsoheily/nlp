Example codes and experiments around natural language processing using TensorFlow, Numpy, Pandas,...

- Word2Vec: Word2vec is a technique for natural language processing to efficiently create word embeddings. The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence.

- TF-IDF: Term Frequency–Inverse Document Frequency (TF-IDF), is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.

- LSA: Latent Semantic Analysis (LSA) is a technique in natural language processing, in particular distributional semantics, of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms. LSA assumes that words that are close in meaning will occur in similar pieces of text.

- Text Classification: text classification is a problem in computer science, while the task is to assign a text to one (or more) classes or categories. There are many interesting applications for text classification such as spam detection and sentiment analysis.
